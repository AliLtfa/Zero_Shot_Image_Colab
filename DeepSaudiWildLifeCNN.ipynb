{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwetfgwe4gr/efed-baedon/blob/main/DeepSaudiWildLifeCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff7967d1",
      "metadata": {
        "id": "ff7967d1"
      },
      "outputs": [],
      "source": [
        "Step 1: Import necessary libraries and load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c2122281",
      "metadata": {
        "id": "c2122281"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4db4c13",
      "metadata": {
        "id": "e4db4c13"
      },
      "outputs": [],
      "source": [
        " Load the dataset by iterating through the folders and creating a list of image paths and their corresponding labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2BnGLQy67nJo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2BnGLQy67nJo",
        "outputId": "7d0df4f4-ef87-46c7-e965-6ec23faab922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2d3eea80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2d3eea80",
        "outputId": "0cb48e13-8cfb-4af3-c942-cb36c9fc039a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Set the path to your dataset folder (inside Google Drive)\n",
        "dataset_dir = '/content/gdrive/MyDrive/Sample'\n",
        "\n",
        "# Create lists to store image paths and labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through the folders\n",
        "for folder in os.listdir(dataset_dir):\n",
        "    folder_path = os.path.join(dataset_dir, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Get the label from the folder name\n",
        "        label = folder\n",
        "\n",
        "        # Iterate through the images in the folder\n",
        "        for file in os.listdir(folder_path):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "                image_paths.append(file_path)\n",
        "                labels.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cy8KWOeiAJ-I",
      "metadata": {
        "id": "Cy8KWOeiAJ-I"
      },
      "outputs": [],
      "source": [
        "# Choose a class to display images from\n",
        "# Note: This is for testing purposes only to find initially if data is correctly loaded\n",
        "class_index = 55  # Choose a class index (0-143)\n",
        "\n",
        "# Get the label of the chosen class\n",
        "class_label = list(set(labels))[class_index]\n",
        "\n",
        "# Get the image paths for the chosen class\n",
        "class_image_paths = [img_path for img_path, label in zip(image_paths, labels) if label == class_label]\n",
        "\n",
        "# Display the first 9 images from the chosen class\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, img_path in enumerate(class_image_paths[:9]):\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(class_label)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6932ee7b",
      "metadata": {
        "id": "6932ee7b"
      },
      "outputs": [],
      "source": [
        "Step 2: Data augmentation and preprocessing\n",
        "\n",
        "Create an ImageDataGenerator to apply data augmentation and preprocessing to the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "19038e34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "19038e34",
        "outputId": "d7af4888-ea0e-41b5-cc24-2e9984ecfd01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 353 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define the data augmentation and preprocessing parameters\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "# Create a data generator for training\n",
        "train_datagen = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(128, 128),  # Resize images to 128x128\n",
        "    batch_size=8,  # Increase batch size\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9af592e",
      "metadata": {
        "id": "f9af592e"
      },
      "outputs": [],
      "source": [
        "Create a CNN model using the keras API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "a5a7f528",
      "metadata": {
        "id": "a5a7f528"
      },
      "outputs": [],
      "source": [
        "# Define the CNN model architecture\n",
        "model = keras.Sequential([\n",
        "layers.Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "layers.MaxPooling2D((2, 2)),\n",
        "layers.Flatten(),\n",
        "layers.Dense(128, activation='relu'),\n",
        "layers.Dropout(0.2),\n",
        "layers.Dense(7, activation='softmax') # 144 classes of animals\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56962472",
      "metadata": {
        "id": "56962472"
      },
      "outputs": [],
      "source": [
        "Compile the model\n",
        "\n",
        "Compile the model with a suitable optimizer and loss function:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "9a257114",
      "metadata": {
        "id": "9a257114"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85a8a31b",
      "metadata": {
        "id": "85a8a31b"
      },
      "outputs": [],
      "source": [
        "Step 5: Train the model\n",
        "\n",
        "Train the model using the fit method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "9d29f2f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9d29f2f6",
        "outputId": "e56ae16c-2d58-4de8-b66e-a6a19fda9d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "45/45 [==============================] - 9s 173ms/step - loss: 3.1074 - accuracy: 0.1785 - val_loss: 1.7923 - val_accuracy: 0.2805\n",
            "Epoch 2/50\n",
            "45/45 [==============================] - 8s 170ms/step - loss: 1.7626 - accuracy: 0.2663 - val_loss: 1.5913 - val_accuracy: 0.4023\n",
            "Epoch 3/50\n",
            "45/45 [==============================] - 8s 168ms/step - loss: 1.5808 - accuracy: 0.3569 - val_loss: 1.4654 - val_accuracy: 0.4788\n",
            "Epoch 4/50\n",
            "45/45 [==============================] - 7s 164ms/step - loss: 1.5041 - accuracy: 0.4674 - val_loss: 1.2197 - val_accuracy: 0.5977\n",
            "Epoch 5/50\n",
            "45/45 [==============================] - 8s 170ms/step - loss: 1.4329 - accuracy: 0.4646 - val_loss: 1.2574 - val_accuracy: 0.5581\n",
            "Epoch 6/50\n",
            "45/45 [==============================] - 8s 169ms/step - loss: 1.2663 - accuracy: 0.5354 - val_loss: 1.1044 - val_accuracy: 0.6176\n",
            "Epoch 7/50\n",
            "45/45 [==============================] - 8s 169ms/step - loss: 1.1920 - accuracy: 0.5779 - val_loss: 1.0686 - val_accuracy: 0.6374\n",
            "Epoch 8/50\n",
            "45/45 [==============================] - 8s 171ms/step - loss: 1.1711 - accuracy: 0.5751 - val_loss: 1.1070 - val_accuracy: 0.5722\n",
            "Epoch 9/50\n",
            "45/45 [==============================] - 7s 168ms/step - loss: 1.0843 - accuracy: 0.6204 - val_loss: 0.8484 - val_accuracy: 0.6884\n",
            "Epoch 10/50\n",
            "45/45 [==============================] - 8s 172ms/step - loss: 0.9937 - accuracy: 0.6346 - val_loss: 0.8574 - val_accuracy: 0.6912\n",
            "Epoch 11/50\n",
            "45/45 [==============================] - 8s 170ms/step - loss: 0.9425 - accuracy: 0.6572 - val_loss: 0.7539 - val_accuracy: 0.7450\n",
            "Epoch 12/50\n",
            "45/45 [==============================] - 7s 166ms/step - loss: 0.8042 - accuracy: 0.7195 - val_loss: 0.7816 - val_accuracy: 0.7450\n",
            "Epoch 13/50\n",
            "45/45 [==============================] - 8s 169ms/step - loss: 0.8186 - accuracy: 0.7422 - val_loss: 0.5792 - val_accuracy: 0.8244\n",
            "Epoch 14/50\n",
            "45/45 [==============================] - 8s 169ms/step - loss: 0.6787 - accuracy: 0.7592 - val_loss: 0.5227 - val_accuracy: 0.8215\n",
            "Epoch 15/50\n",
            "45/45 [==============================] - 7s 166ms/step - loss: 0.7199 - accuracy: 0.7450 - val_loss: 0.5795 - val_accuracy: 0.8159\n",
            "Epoch 16/50\n",
            "45/45 [==============================] - 8s 171ms/step - loss: 0.6928 - accuracy: 0.7479 - val_loss: 0.4795 - val_accuracy: 0.8357\n",
            "Epoch 17/50\n",
            "45/45 [==============================] - 7s 166ms/step - loss: 0.7481 - accuracy: 0.7139 - val_loss: 0.4422 - val_accuracy: 0.8612\n",
            "Epoch 18/50\n",
            "45/45 [==============================] - 7s 166ms/step - loss: 0.5798 - accuracy: 0.7677 - val_loss: 0.3940 - val_accuracy: 0.8782\n",
            "Epoch 19/50\n",
            "45/45 [==============================] - 8s 168ms/step - loss: 0.5718 - accuracy: 0.7819 - val_loss: 0.3764 - val_accuracy: 0.8895\n",
            "Epoch 20/50\n",
            "45/45 [==============================] - 7s 165ms/step - loss: 0.4868 - accuracy: 0.8272 - val_loss: 0.3537 - val_accuracy: 0.9178\n",
            "Epoch 21/50\n",
            "45/45 [==============================] - 7s 168ms/step - loss: 0.4324 - accuracy: 0.8640 - val_loss: 0.3159 - val_accuracy: 0.9178\n",
            "Epoch 22/50\n",
            "45/45 [==============================] - 8s 171ms/step - loss: 0.4420 - accuracy: 0.8555 - val_loss: 0.2927 - val_accuracy: 0.9490\n",
            "Epoch 23/50\n",
            "45/45 [==============================] - 7s 168ms/step - loss: 0.4035 - accuracy: 0.8612 - val_loss: 0.3463 - val_accuracy: 0.8754\n",
            "Epoch 24/50\n",
            "45/45 [==============================] - 7s 165ms/step - loss: 0.5001 - accuracy: 0.8470 - val_loss: 0.2633 - val_accuracy: 0.9348\n",
            "Epoch 25/50\n",
            "45/45 [==============================] - 7s 163ms/step - loss: 0.4353 - accuracy: 0.8470 - val_loss: 0.2565 - val_accuracy: 0.9263\n",
            "Epoch 26/50\n",
            "45/45 [==============================] - 8s 169ms/step - loss: 0.4099 - accuracy: 0.8555 - val_loss: 0.3041 - val_accuracy: 0.9433\n",
            "Epoch 27/50\n",
            "45/45 [==============================] - 8s 171ms/step - loss: 0.3541 - accuracy: 0.8725 - val_loss: 0.2734 - val_accuracy: 0.9178\n",
            "Epoch 28/50\n",
            "45/45 [==============================] - 7s 166ms/step - loss: 0.3706 - accuracy: 0.8839 - val_loss: 0.1965 - val_accuracy: 0.9433\n",
            "Epoch 29/50\n",
            "45/45 [==============================] - 7s 168ms/step - loss: 0.3391 - accuracy: 0.8895 - val_loss: 0.2603 - val_accuracy: 0.9093\n",
            "Epoch 30/50\n",
            "45/45 [==============================] - 8s 171ms/step - loss: 0.3665 - accuracy: 0.8810 - val_loss: 0.2070 - val_accuracy: 0.9462\n",
            "Epoch 31/50\n",
            "45/45 [==============================] - 7s 167ms/step - loss: 0.3154 - accuracy: 0.9122 - val_loss: 0.1481 - val_accuracy: 0.9717\n",
            "Epoch 32/50\n",
            "45/45 [==============================] - 8s 170ms/step - loss: 0.2149 - accuracy: 0.9377 - val_loss: 0.1079 - val_accuracy: 0.9830\n",
            "Epoch 33/50\n",
            "45/45 [==============================] - 7s 166ms/step - loss: 0.2231 - accuracy: 0.9405 - val_loss: 0.1358 - val_accuracy: 0.9717\n",
            "Epoch 34/50\n",
            "45/45 [==============================] - 8s 171ms/step - loss: 0.2084 - accuracy: 0.9405 - val_loss: 0.1161 - val_accuracy: 0.9717\n",
            "Epoch 35/50\n",
            "45/45 [==============================] - 8s 171ms/step - loss: 0.2228 - accuracy: 0.9263 - val_loss: 0.1100 - val_accuracy: 0.9802\n",
            "Epoch 36/50\n",
            "45/45 [==============================] - 7s 168ms/step - loss: 0.2051 - accuracy: 0.9433 - val_loss: 0.1327 - val_accuracy: 0.9632\n",
            "Epoch 37/50\n",
            "45/45 [==============================] - 8s 172ms/step - loss: 0.2500 - accuracy: 0.9263 - val_loss: 0.1626 - val_accuracy: 0.9547\n",
            "Epoch 38/50\n",
            "45/45 [==============================] - 8s 174ms/step - loss: 0.2513 - accuracy: 0.9235 - val_loss: 0.1257 - val_accuracy: 0.9745\n",
            "Epoch 39/50\n",
            "45/45 [==============================] - 7s 167ms/step - loss: 0.2860 - accuracy: 0.9178 - val_loss: 0.1783 - val_accuracy: 0.9490\n",
            "Epoch 40/50\n",
            "45/45 [==============================] - 8s 175ms/step - loss: 0.2443 - accuracy: 0.9263 - val_loss: 0.1209 - val_accuracy: 0.9745\n",
            "Epoch 41/50\n",
            "45/45 [==============================] - 8s 173ms/step - loss: 0.2380 - accuracy: 0.9433 - val_loss: 0.0963 - val_accuracy: 0.9858\n",
            "Epoch 42/50\n",
            "45/45 [==============================] - 8s 174ms/step - loss: 0.1918 - accuracy: 0.9405 - val_loss: 0.1266 - val_accuracy: 0.9660\n",
            "Epoch 43/50\n",
            "45/45 [==============================] - 8s 173ms/step - loss: 0.1836 - accuracy: 0.9377 - val_loss: 0.1630 - val_accuracy: 0.9490\n",
            "Epoch 44/50\n",
            "45/45 [==============================] - 8s 173ms/step - loss: 0.2044 - accuracy: 0.9433 - val_loss: 0.1156 - val_accuracy: 0.9660\n",
            "Epoch 45/50\n",
            "45/45 [==============================] - 8s 175ms/step - loss: 0.2169 - accuracy: 0.9348 - val_loss: 0.0896 - val_accuracy: 0.9802\n",
            "Epoch 46/50\n",
            "45/45 [==============================] - 8s 169ms/step - loss: 0.1469 - accuracy: 0.9603 - val_loss: 0.0488 - val_accuracy: 0.9972\n",
            "Epoch 47/50\n",
            "45/45 [==============================] - 7s 168ms/step - loss: 0.1920 - accuracy: 0.9518 - val_loss: 0.1211 - val_accuracy: 0.9603\n",
            "Epoch 48/50\n",
            "45/45 [==============================] - 8s 174ms/step - loss: 0.1909 - accuracy: 0.9348 - val_loss: 0.1340 - val_accuracy: 0.9745\n",
            "Epoch 49/50\n",
            "45/45 [==============================] - 8s 173ms/step - loss: 0.2873 - accuracy: 0.9207 - val_loss: 0.1073 - val_accuracy: 0.9660\n",
            "Epoch 50/50\n",
            "45/45 [==============================] - 8s 170ms/step - loss: 0.2622 - accuracy: 0.9178 - val_loss: 0.1041 - val_accuracy: 0.9745\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_datagen,\n",
        "    epochs=50,\n",
        "    validation_data=train_datagen,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "id": "e2e41979",
      "metadata": {
        "id": "e2e41979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "18bc5cfd-537e-46f5-c135-301e92e7aa2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x78d45019da20> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x78d45019da20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x78d45019da20> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x78d45019da20>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        }
      ],
      "source": [
        "#Export CNN Model\n",
        "import tensorflow as tf\n",
        "# Save the Keras model to a file\n",
        "model.save('animal_classification_model.pb') #or .h5 , it's almost same for deployment on apps but pb is more convertable.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing The Model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('animal_classification_model.pb')\n",
        "\n",
        "# Get the list of folders (classes)\n",
        "folders = os.listdir('/content/gdrive/MyDrive/Sample')\n",
        "\n",
        "# Upload an image from your PC\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded image file\n",
        "image_file = list(uploaded.keys())[0]\n",
        "\n",
        "# Open the image file using PIL\n",
        "image = Image.open(image_file)\n",
        "\n",
        "# Resize the image to the model's input shape\n",
        "image = image.resize((128, 128))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_array = np.array(image) / 255.0\n",
        "\n",
        "# Add a batch dimension to the image array\n",
        "image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "# Make predictions on the uploaded image\n",
        "predictions = model.predict(image_array)\n",
        "\n",
        "# Get the predicted class index\n",
        "predicted_index = np.argmax(predictions)\n",
        "\n",
        "# Get the corresponding folder name (class)\n",
        "predicted_class = folders[predicted_index]\n",
        "\n",
        "# Print the predicted class\n",
        "print(f\"Predicted class: {predicted_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "HWMz4N7e52KE",
        "outputId": "d03eca95-f8ab-4f91-b2cf-e803c5713fa8"
      },
      "id": "HWMz4N7e52KE",
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bbc6f169-1bd6-454c-9b9b-75596a523a99\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bbc6f169-1bd6-454c-9b9b-75596a523a99\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sand-cat-1024x768.jpg.webp to sand-cat-1024x768.jpg (6).webp\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Predicted class: sand cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Indexes for Later Use (json and csv)\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "\n",
        "# Get the list of folders (classes)\n",
        "folders = os.listdir('/content/gdrive/MyDrive/Sample')\n",
        "\n",
        "# Create a dictionary to map indexes to labels\n",
        "index_to_label = {i: folder for i, folder in enumerate(folders)}\n",
        "\n",
        "# Export to JSON file\n",
        "with open('index_to_label.json', 'w') as f:\n",
        "    json.dump(index_to_label, f)\n",
        "\n",
        "# Export to CSV file\n",
        "with open('index_to_label.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Index', 'Label'])\n",
        "    for index, label in index_to_label.items():\n",
        "        writer.writerow([index, label])"
      ],
      "metadata": {
        "id": "Ts7YZiYS71oZ"
      },
      "id": "Ts7YZiYS71oZ",
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to Tensorflow lite for mobile use\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('animal_classification_model.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"animal_classification_model\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DRUj103m5gdu",
        "outputId": "44950261-22b7-4b5d-82a9-2a5c85056e49"
      },
      "id": "DRUj103m5gdu",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32521672"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGq6wFZLUx8u"
      },
      "id": "kGq6wFZLUx8u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdr6jot5-cgq"
      },
      "id": "mdr6jot5-cgq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}